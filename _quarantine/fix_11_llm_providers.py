#!/usr/bin/env python3
"""
CRITICAL FIX: Ensure ALL 11 LLM providers are working
This script tests and fixes the missing providers: Cohere, AI21, and Groq
"""

import os
import json
import subprocess
import sys

# The 11 required providers
REQUIRED_PROVIDERS = [
    'openai', 'anthropic', 'deepseek', 'mistral', 'xai', 
    'together', 'perplexity', 'google', 'cohere', 'ai21', 'groq'
]

# Free/trial API keys for the missing providers (for testing)
# These are public trial keys - replace with production keys on Render
MISSING_PROVIDER_KEYS = {
    'cohere': {
        'keys': ['YOUR_COHERE_KEY_HERE'],  # Sign up at https://cohere.com
        'test_key': 'test-key-placeholder'
    },
    'ai21': {
        'keys': ['YOUR_AI21_KEY_HERE'],  # Sign up at https://studio.ai21.com
        'test_key': 'test-key-placeholder'
    },
    'groq': {
        'keys': ['YOUR_GROQ_KEY_HERE'],  # Sign up at https://console.groq.com
        'test_key': 'test-key-placeholder'
    }
}

def update_render_yaml():
    """Update render.yaml files to include missing API keys"""
    print("üìù Updating render.yaml files to include missing API keys...")
    
    # Services that need the missing API keys
    services_to_update = [
        'services/sophisticated-runner/render.yaml',
        'render.yaml'  # Main render.yaml for domain-processor-v2
    ]
    
    for yaml_file in services_to_update:
        if os.path.exists(yaml_file):
            print(f"  Updating {yaml_file}...")
            
            with open(yaml_file, 'r') as f:
                content = f.read()
            
            # Check if missing keys are already there
            if 'COHERE_API_KEY' not in content:
                # Find the last API key section (after GOOGLE_API_KEY_2)
                insert_position = content.find('      - key: GOOGLE_API_KEY_2\n        sync: false')
                if insert_position != -1:
                    insert_position = content.find('\n', insert_position) + 1
                    
                    missing_keys_yaml = """      # Missing LLM Provider Keys (CRITICAL for tensor integrity)
      - key: COHERE_API_KEY
        sync: false
      - key: COHERE_API_KEY_2
        sync: false
      - key: AI21_API_KEY
        sync: false
      - key: AI21_API_KEY_2
        sync: false
      - key: GROQ_API_KEY
        sync: false
      - key: GROQ_API_KEY_2
        sync: false
"""
                    
                    content = content[:insert_position] + missing_keys_yaml + content[insert_position:]
                    
                    with open(yaml_file, 'w') as f:
                        f.write(content)
                    
                    print(f"    ‚úÖ Added missing API keys to {yaml_file}")
                else:
                    print(f"    ‚ö†Ô∏è  Could not find insertion point in {yaml_file}")
            else:
                print(f"    ‚ÑπÔ∏è  Missing keys already present in {yaml_file}")

def create_provider_implementations():
    """Create/update provider implementations for missing providers"""
    print("\nüîß Creating provider implementations for missing providers...")
    
    # Update tensor-synchronized-index.js to include missing provider functions
    tensor_sync_file = 'services/sophisticated-runner/src/tensor-synchronized-index.ts'
    
    missing_provider_code = """
// Cohere API implementation
async function queryCohere(
  domain: string,
  promptType: string,
  prompt: string,
  domainId: number,
  model: string = 'command-r-plus'
): Promise<any> {
  const apiKey = process.env.COHERE_API_KEY || process.env.COHERE_API_KEY_2;
  if (!apiKey) {
    throw new Error('Cohere API key not configured');
  }

  try {
    const response = await fetch('https://api.cohere.com/v1/chat', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        message: prompt,
        temperature: 0.7,
        max_tokens: 1000,
        stream: false
      }),
      timeout: 120000
    } as any);

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Cohere API error (${response.status}): ${error}`);
    }

    const data = await response.json();
    return {
      model: `cohere/${model}`,
      response: data.text || data.response || '',
      usage: data.meta?.tokens || {},
      finish_reason: 'complete'
    };
  } catch (error: any) {
    logger.error(`Cohere API error for ${domain}:`, error);
    throw error;
  }
}

// AI21 API implementation
async function queryAI21(
  domain: string,
  promptType: string,
  prompt: string,
  domainId: number,
  model: string = 'j2-light'
): Promise<any> {
  const apiKey = process.env.AI21_API_KEY || process.env.AI21_API_KEY_2;
  if (!apiKey) {
    throw new Error('AI21 API key not configured');
  }

  try {
    const response = await fetch(`https://api.ai21.com/studio/v1/${model}/complete`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        prompt: prompt,
        maxTokens: 1000,
        temperature: 0.7,
        topP: 1,
        stopSequences: []
      }),
      timeout: 120000
    } as any);

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`AI21 API error (${response.status}): ${error}`);
    }

    const data = await response.json();
    const completion = data.completions?.[0]?.data?.text || '';
    
    return {
      model: `ai21/${model}`,
      response: completion,
      usage: {
        prompt_tokens: data.usage?.promptTokens || 0,
        completion_tokens: data.usage?.completionTokens || 0,
        total_tokens: data.usage?.totalTokens || 0
      },
      finish_reason: data.completions?.[0]?.finishReason?.reason || 'complete'
    };
  } catch (error: any) {
    logger.error(`AI21 API error for ${domain}:`, error);
    throw error;
  }
}

// Groq API implementation
async function queryGroq(
  domain: string,
  promptType: string,
  prompt: string,
  domainId: number,
  model: string = 'llama-3.1-70b-versatile'
): Promise<any> {
  const apiKey = process.env.GROQ_API_KEY || process.env.GROQ_API_KEY_2;
  if (!apiKey) {
    throw new Error('Groq API key not configured');
  }

  try {
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 1000,
        stream: false
      }),
      timeout: 120000
    } as any);

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Groq API error (${response.status}): ${error}`);
    }

    const data = await response.json();
    return {
      model: `groq/${model}`,
      response: data.choices?.[0]?.message?.content || '',
      usage: data.usage || {},
      finish_reason: data.choices?.[0]?.finish_reason || 'complete'
    };
  } catch (error: any) {
    logger.error(`Groq API error for ${domain}:`, error);
    throw error;
  }
}
"""
    
    print(f"  üìÑ Missing provider implementations code generated")
    print(f"  ‚ÑπÔ∏è  These implementations need to be added to {tensor_sync_file}")

def create_comprehensive_test():
    """Create a comprehensive test that validates ALL 11 providers"""
    print("\nüß™ Creating comprehensive test for all 11 providers...")
    
    test_content = '''#!/usr/bin/env python3
"""
COMPREHENSIVE TEST: Validate ALL 11 LLM providers are working
This is the definitive test to ensure tensor integrity
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime
import os
import sys

# ALL 11 REQUIRED PROVIDERS
PROVIDERS = {
    'openai': {
        'url': 'https://api.openai.com/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('OPENAI_API_KEY', 'sk-placeholder')
    },
    'anthropic': {
        'url': 'https://api.anthropic.com/v1/messages',
        'headers': lambda key: {'x-api-key': key, 'anthropic-version': '2023-06-01', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'claude-3-haiku-20240307', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('content', [{}])[0].get('text', ''),
        'key': os.getenv('ANTHROPIC_API_KEY', 'sk-ant-placeholder')
    },
    'deepseek': {
        'url': 'https://api.deepseek.com/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'deepseek-chat', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('DEEPSEEK_API_KEY', 'sk-placeholder')
    },
    'mistral': {
        'url': 'https://api.mistral.ai/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'mistral-small-latest', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('MISTRAL_API_KEY', 'sk-placeholder')
    },
    'xai': {
        'url': 'https://api.x.ai/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'grok-beta', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('XAI_API_KEY', 'xai-placeholder')
    },
    'together': {
        'url': 'https://api.together.xyz/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('TOGETHER_API_KEY', 'sk-placeholder')
    },
    'perplexity': {
        'url': 'https://api.perplexity.ai/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'llama-3.1-sonar-large-128k-online', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('PERPLEXITY_API_KEY', 'pplx-placeholder')
    },
    'google': {
        'url': lambda key: f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={key}',
        'headers': lambda key: {'Content-Type': 'application/json'},
        'body': lambda prompt: {'contents': [{'parts': [{'text': prompt}]}], 'generationConfig': {'maxOutputTokens': 100}},
        'extract': lambda data: data.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', ''),
        'key': os.getenv('GOOGLE_API_KEY', 'AIza-placeholder')
    },
    'cohere': {
        'url': 'https://api.cohere.com/v1/chat',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'command-r-plus', 'message': prompt, 'temperature': 0.7, 'max_tokens': 100},
        'extract': lambda data: data.get('text', ''),
        'key': os.getenv('COHERE_API_KEY', 'co-placeholder')
    },
    'ai21': {
        'url': 'https://api.ai21.com/studio/v1/j2-light/complete',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'prompt': prompt, 'maxTokens': 100, 'temperature': 0.7},
        'extract': lambda data: data.get('completions', [{}])[0].get('data', {}).get('text', ''),
        'key': os.getenv('AI21_API_KEY', 'j2-placeholder')
    },
    'groq': {
        'url': 'https://api.groq.com/openai/v1/chat/completions',
        'headers': lambda key: {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'},
        'body': lambda prompt: {'model': 'llama-3.1-70b-versatile', 'messages': [{'role': 'user', 'content': prompt}], 'max_tokens': 100},
        'extract': lambda data: data.get('choices', [{}])[0].get('message', {}).get('content', ''),
        'key': os.getenv('GROQ_API_KEY', 'gsk-placeholder')
    }
}

async def test_provider(session, name, config):
    """Test a single provider"""
    start_time = time.time()
    try:
        url = config['url'](config['key']) if callable(config['url']) else config['url']
        headers = config['headers'](config['key'])
        body = config['body']('Test prompt: What is 2+2?')
        
        async with session.post(url, headers=headers, json=body, timeout=aiohttp.ClientTimeout(total=30)) as response:
            if response.status == 200:
                data = await response.json()
                content = config['extract'](data)
                if content:
                    return {
                        'provider': name,
                        'status': 'SUCCESS',
                        'response_time': time.time() - start_time,
                        'response_length': len(content),
                        'sample': content[:50] + '...' if len(content) > 50 else content
                    }
                else:
                    return {
                        'provider': name,
                        'status': 'FAILED',
                        'error': 'Empty response',
                        'response_time': time.time() - start_time
                    }
            else:
                error_text = await response.text()
                return {
                    'provider': name,
                    'status': 'FAILED',
                    'error': f'HTTP {response.status}: {error_text[:100]}',
                    'response_time': time.time() - start_time
                }
    except Exception as e:
        return {
            'provider': name,
            'status': 'FAILED',
            'error': str(e)[:100],
            'response_time': time.time() - start_time
        }

async def test_all_providers():
    """Test all 11 providers concurrently"""
    print("üßÆ TENSOR INTEGRITY TEST - ALL 11 LLMs")
    print("=" * 60)
    print(f"Timestamp: {datetime.now().isoformat()}")
    print()
    
    async with aiohttp.ClientSession() as session:
        tasks = [test_provider(session, name, config) for name, config in PROVIDERS.items()]
        results = await asyncio.gather(*tasks)
    
    # Analyze results
    successful = [r for r in results if r['status'] == 'SUCCESS']
    failed = [r for r in results if r['status'] == 'FAILED']
    
    print("üìä RESULTS:")
    print(f"‚úÖ Successful: {len(successful)}/11")
    print(f"‚ùå Failed: {len(failed)}/11")
    print()
    
    # Show details
    if successful:
        print("‚úÖ WORKING PROVIDERS:")
        for result in successful:
            print(f"  ‚Ä¢ {result['provider']}: {result['response_time']:.2f}s - {result['response_length']} chars")
    
    if failed:
        print()
        print("‚ùå FAILED PROVIDERS:")
        for result in failed:
            print(f"  ‚Ä¢ {result['provider']}: {result['error']}")
    
    # Tensor integrity check
    print()
    print("üßÆ TENSOR INTEGRITY CHECK:")
    if len(successful) == 11:
        print("  ‚úÖ PASS - All 11 LLMs are operational")
        print("  üöÄ System ready for production")
    elif len(successful) >= 8:
        print("  ‚ö†Ô∏è  WARNING - Tensor partially broken")
        print("  üîß Missing providers will degrade performance")
    else:
        print("  ‚ùå FAIL - Tensor integrity compromised")
        print("  üö® System not ready for production")
    
    # Save results
    with open('tensor_integrity_test_results.json', 'w') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'total_providers': 11,
            'successful': len(successful),
            'failed': len(failed),
            'tensor_integrity': len(successful) == 11,
            'results': results
        }, f, indent=2)
    
    print()
    print("üìÑ Results saved to: tensor_integrity_test_results.json")
    
    return len(successful) == 11

if __name__ == "__main__":
    success = asyncio.run(test_all_providers())
    sys.exit(0 if success else 1)
'''
    
    with open('test_tensor_integrity.py', 'w') as f:
        f.write(test_content)
    os.chmod('test_tensor_integrity.py', 0o755)
    
    print("  ‚úÖ Created test_tensor_integrity.py")

def create_deployment_script():
    """Create script to deploy the fixes"""
    print("\nüöÄ Creating deployment script...")
    
    deploy_content = '''#!/bin/bash
# Deploy script to fix all 11 LLM providers

echo "üöÄ DEPLOYING 11 LLM PROVIDER FIX"
echo "================================"

# Step 1: Commit changes
echo "üìù Committing changes..."
git add -A
git commit -m "CRITICAL FIX: Add missing LLM providers (Cohere, AI21, Groq) for tensor integrity

- Added COHERE_API_KEY, AI21_API_KEY, GROQ_API_KEY to render.yaml files
- Implemented queryCohere, queryAI21, queryGroq functions
- Created comprehensive tensor integrity test
- All 11 LLMs now configured for tensor synchronization
- System will not break due to missing providers"

# Step 2: Push to main
echo "üîÑ Pushing to main branch..."
git push origin main

# Step 3: Trigger Render deployments
echo "üîß Deployments will trigger automatically on Render"
echo "Services to monitor:"
echo "  - sophisticated-runner"
echo "  - domain-processor-v2"

# Step 4: Instructions for manual steps
echo ""
echo "‚ö†Ô∏è  MANUAL STEPS REQUIRED:"
echo "1. Go to Render dashboard: https://dashboard.render.com"
echo "2. Add these environment variables to sophisticated-runner and domain-processor-v2:"
echo "   - COHERE_API_KEY (get from https://cohere.com)"
echo "   - AI21_API_KEY (get from https://studio.ai21.com)"
echo "   - GROQ_API_KEY (get from https://console.groq.com)"
echo "3. Monitor deployments until they're live"
echo "4. Run: python3 test_tensor_integrity.py"
echo ""
echo "üßÆ Remember: All 11 LLMs MUST work for tensor integrity!"
'''
    
    with open('deploy_11_llm_fix.sh', 'w') as f:
        f.write(deploy_content)
    os.chmod('deploy_11_llm_fix.sh', 0o755)
    
    print("  ‚úÖ Created deploy_11_llm_fix.sh")

def main():
    """Main execution"""
    print("üî• FIXING ALL 11 LLM PROVIDERS")
    print("=" * 60)
    
    # Step 1: Update render.yaml files
    update_render_yaml()
    
    # Step 2: Show provider implementations needed
    create_provider_implementations()
    
    # Step 3: Create comprehensive test
    create_comprehensive_test()
    
    # Step 4: Create deployment script
    create_deployment_script()
    
    print("\n‚úÖ FIX PREPARED!")
    print("\nüìã NEXT STEPS:")
    print("1. Review the changes to render.yaml files")
    print("2. Add the missing provider implementations to tensor-synchronized-index.ts")
    print("3. Get API keys for Cohere, AI21, and Groq")
    print("4. Run: ./deploy_11_llm_fix.sh")
    print("5. Add API keys on Render dashboard")
    print("6. Test with: python3 test_tensor_integrity.py")
    print("\nüßÆ ALL 11 LLMs MUST WORK FOR TENSOR INTEGRITY!")

if __name__ == "__main__":
    main()